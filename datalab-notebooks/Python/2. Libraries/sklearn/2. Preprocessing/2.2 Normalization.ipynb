{"cells":[{"cell_type":"markdown","source":["# Normalization"],"metadata":{}},{"cell_type":"markdown","source":["## Table of Contents\n\n1. Introduction to Normalization\n1. Function `normalize`\n1. Utility class `Normalizer` \n1. Using `Normalizer` in a pipeline"],"metadata":{}},{"cell_type":"markdown","source":["## Introduction to Normalization"],"metadata":{}},{"cell_type":"markdown","source":["Normalization is the process of scaling individual samples to have unit norm. It is the numeric values in a row that collectively have unit norm. This assumption is the basis of the Vector Space Model often used in text classification and clustering contexts. \n\nAbout Vector Space Model:\n- https://en.wikipedia.org/wiki/Vector_space_model"],"metadata":{}},{"cell_type":"markdown","source":["Load libraries."],"metadata":{}},{"cell_type":"code","source":["from sklearn import preprocessing\nimport numpy as np"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Function `normalize`"],"metadata":{}},{"cell_type":"markdown","source":["Transform a toy dataset `X` using the `normalize` function. Then store the normalized data in an object `X_normalized`."],"metadata":{}},{"cell_type":"code","source":["X = [[ 1., -1.,  2.],\n     [ 2.,  0.,  0.],\n     [ 0.,  1., -2.]]\nX_normalized = preprocessing.normalize(X, norm='l2')\nX_normalized                                      "],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["In the above output, the sum of the squares of the elements of each row are equal to `1` as is shown in the following cell."],"metadata":{}},{"cell_type":"code","source":["X_normalized[0,:], X_normalized[0,:]**2, np.sum(X_normalized[0,:]**2), np.sqrt(np.sum(X_normalized[0,:]**2))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["In the above example, the normalized vectors in `X_normalized` are calculated using the 'l2' norm \n\n\\\\(z = \\sqrt{\\sum_{i=1}^n x^2_i}\\\\)  \n\nDivide each non-zero component in `X` by the square root of the sum of the squares of each component in `X`. \n\nThe 'l1' norm is defined as\n\n\\\\(z = \\sum_{i=1}^n \\|x_i| \\\\) \n\nDivide each non-zero component in `X` by the sum of the absolute values of each components in the vector.\n\nThe 'max' norm is defined as\n\n\\\\(z = \\max {x_i} \\\\) \n\nDivide each non-zero component in `X` by the maximum value in the vector."],"metadata":{}},{"cell_type":"markdown","source":["Transform the dataset `X` using the `normalize` function with 'l1' norm. Then store the normalized data in a object `X_normalized_l1`."],"metadata":{}},{"cell_type":"code","source":["X_normalized_l1 = preprocessing.normalize(X, norm='l1')\nX_normalized_l1"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Transform the dataset `X` using the `normalize` function with 'max' norm. Then store the normalized data in a object `X_normalized_m`. Note that using 'max' norm does not take absolute values first, so the third vector is `[0,1,-2]`."],"metadata":{}},{"cell_type":"code","source":["X_normalized_m = preprocessing.normalize(X, norm='max')\nX_normalized_m"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["###`Normalizer`"],"metadata":{}},{"cell_type":"markdown","source":["The `preprocessing` module in scikit-learn further provides a utility class `Normalizer` that implements the same operation using the Transformer API. The fit method is useless in this case: this operation treats samples independently. The fit method is useful when used in a pipeline."],"metadata":{}},{"cell_type":"markdown","source":["Create an object `normalizer`."],"metadata":{}},{"cell_type":"code","source":["normalizer = preprocessing.Normalizer()\nnormalizer"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["The `normalizer` instance can then be used on sample vectors as an transformer. The transform method scales each non zero row of X to unit norm."],"metadata":{}},{"cell_type":"code","source":["normalizer.transform(X) "],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["The transform method scales the sample vectors to unit norm."],"metadata":{}},{"cell_type":"code","source":["normalizer.transform([[-1.,  1., 0.]]) "],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["The above session introduces a quick and easy way to implement normalization on single dataset and using the `Normalizer` class which can scale features to unit norm and be useful in the early steps of a `sklearn.pipeline.Pipeline`."],"metadata":{}},{"cell_type":"markdown","source":["### Using `Normalizer` in a pipeline"],"metadata":{}},{"cell_type":"markdown","source":["Here is an example shows whether or not normalizing the features of the California Housing Prices dataset has any impact on the performance of a k-Nearest-Neighbors estimator."],"metadata":{}},{"cell_type":"markdown","source":["Load libraries."],"metadata":{}},{"cell_type":"code","source":["from sklearn.preprocessing import Normalizer\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.metrics import mean_squared_error"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Read the dataset using the `fetch_california_housing` function and then split it into train and test using the `train_test_split` function."],"metadata":{}},{"cell_type":"code","source":["dataset = fetch_california_housing()\nX_full, y_full = dataset.data, dataset.target\nX_train, X_test, y_train, y_test=train_test_split(X_full,y_full,test_size=0.2, random_state=20)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["Here we use a k-nearest neighbors regressor as part of a pipeline that includes normalizing, and for the purposes of comparison, a knn regressor trained on the unnormalized data has been provided in the following code cell."],"metadata":{}},{"cell_type":"code","source":["steps=[('normalizer', Normalizer()),\n       ('knn',        KNeighborsRegressor())]\n\npipeline=Pipeline(steps)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["Fit the pipeline using `X_train` as training data and `y_train` as target values, and pass the computed parameters to an object `knn_normalized`. Also, fit a knn regressor using unnormalized training data and pass the computed parameters to the object `knn_unnormalized`."],"metadata":{}},{"cell_type":"code","source":["knn_normalized = pipeline.fit(X_train, y_train)\nknn_unnormalized = KNeighborsRegressor().fit(X_train, y_train)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["Compute and print metrics."],"metadata":{}},{"cell_type":"code","source":["print('Prediction Error with normalization: {}'.format(mean_squared_error(y_test, knn_normalized.predict(X_test))))\nprint('Prediction Error without normalization: {}'.format(mean_squared_error(y_test, knn_unnormalized.predict(X_test))))"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["The output above shows that normalization has significantly improved the performance of k-nearest neighbors regressor in predicting using the California Housing Prices dataset."],"metadata":{}}],"metadata":{"name":"2.2 Normalization","notebookId":409726},"nbformat":4,"nbformat_minor":0}