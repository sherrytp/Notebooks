{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.0 Introduction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-space/datalab-notebooks/blob/master/Python/4.%20Workflows/1.0%20Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GoVnL7QRPGk",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Machine Learning Workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCKTqMUFRPGp",
        "colab_type": "text"
      },
      "source": [
        "## Reference\n",
        "- https://scikit-learn.org/stable/index.html\n",
        "- https://scikit-learn.org/stable/datasets/index.html\n",
        "- https://scikit-learn.org/stable/data_transforms.html\n",
        "- https://scikit-learn.org/stable/supervised_learning.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "- https://github.com/data-space/datalab-notebooks/tree/master/Python/3.%20Pipelines\n",
        "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCeZm-TwRPGq",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "1. Introduction\n",
        "1. Setup\n",
        "1. Workflow - demonstration\n",
        "1. Workflow - essentials\n",
        "1. Workflow - function\n",
        "1. Workflow - Boston housing dataset\n",
        "1. Workflow - Diamonds dataset (hands-on)\n",
        "1. Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GM-mxEURPGr",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UAfDppwRPG2",
        "colab_type": "text"
      },
      "source": [
        "Supervised machine learning has the general goal of creating a model/method to make _good_ predictions on unseen data. \n",
        "\n",
        "Machine learning workflows (for supervised learning) organize the steps that accomplish this goal. These steps are:\n",
        "1. Get the initial dataset\n",
        "2. Create a feature-target dataset (from the initial dataset)\n",
        "3. Create train and test datasets (from the feature-target dataset)\n",
        "4. Fit a model (to the train dataset)\n",
        "5. Make and evaluate predictions (made by the fit model on the test dataset)\n",
        "\n",
        "There are four components (that you provide) as input to the workflow:\n",
        "1. The initial dataset\n",
        "2. The process to create the feature-target dataset\n",
        "3. The process to fit the model\n",
        "4. The choice of metric to use in evaluating the model predictions\n",
        "\n",
        "Our focus is on:\n",
        "- component 2 and the processes to prepare the data in step 2\n",
        "- component 3 and the process to fit the model in step 4\n",
        "\n",
        "In this notebook, these steps will be described and implemented in Python code and run with two simple datasets. \n",
        "\n",
        "Later notebooks will implement this workflow with more involved datasets which will provide opportunities to focus on steps 2 and 4. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9UElX2S2Ap4",
        "colab_type": "text"
      },
      "source": [
        "There are a few requirements of the workflow. In general, information used to evaluate the model should not be available when creating the model. Specifically, \n",
        "- the train dataset should be used to fit the model\n",
        "- the test dataset should be used to evaluate the model\n",
        "- step 5 should only be run once\n",
        "- the feature-target dataset should be created using only \"per-row\" transformations\n",
        "- predictor columns of the feature-target dataset should have only numeric types \n",
        "\n",
        "The first two requirements will be implemented in the code below. The remaining requirements will be discussed in later notebooks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wfU4tsH5U5X",
        "colab_type": "text"
      },
      "source": [
        "The takeaways from this notebook are:\n",
        "- workflow steps\n",
        "- workflow components\n",
        "- the realization that this workflow isn't really that difficult \n",
        "\n",
        "The requirements will be revisited in later notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTcFuxVEFTaF",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoXXxsa5I7rI",
        "colab_type": "text"
      },
      "source": [
        "This section loads three libraries and displays their version numbers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxIsWumyRPGt",
        "colab_type": "text"
      },
      "source": [
        "Import the `pandas`,  `numpy` and `sklearn` libraries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iKsgHXpRPGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas  as pd\n",
        "import numpy   as np\n",
        "import sklearn as sk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_53LqmHxRPGy",
        "colab_type": "text"
      },
      "source": [
        "Display the version numbers of the `pandas`, `numpy` and `sklearn` packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVpiFs1MRPGz",
        "colab_type": "code",
        "outputId": "fb3cbfb1-1236-44f9-8160-071c0c02c4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print('pandas :',pd.__version__)\n",
        "print('numpy  :',np.__version__)\n",
        "print('sklearn:',sk.__version__)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pandas : 0.24.2\n",
            "numpy  : 1.16.4\n",
            "sklearn: 0.21.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrHTzAV_ivtk",
        "colab_type": "text"
      },
      "source": [
        "## Workflow - demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaC1Qts4RYsW",
        "colab_type": "text"
      },
      "source": [
        "Each section below explains a step of the workflow and implements the step in Python. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FunnoU-vJqJf",
        "colab_type": "text"
      },
      "source": [
        "### Step 1. Get initial dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGyFIRu-TleL",
        "colab_type": "text"
      },
      "source": [
        "This step is implemented with a single Python function (`get_iris_pdf`) that reads data from its source and returns a pandas dataframe (`pdf`). The function retrieves the iris dataset from the `sklearn.datasets` module and returns the features and target concatenated into a single dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4eL3gpmKt3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_iris_pdf():\n",
        "  import pandas as pd\n",
        "  from sklearn.datasets import load_iris\n",
        "  iris_features     = load_iris().data\n",
        "  iris_target       = load_iris().target\n",
        "  iris_target_names = load_iris().target_names\n",
        "\n",
        "  iris_feature_columns = [feature_name.replace(' ','_')\n",
        "                                      .replace('(','')\n",
        "                                      .replace(')','') \n",
        "                          for feature_name in load_iris().get('feature_names')]\n",
        "  \n",
        "  iris_features_pdf = pd.DataFrame(data=iris_features,\n",
        "                                   columns=iris_feature_columns\n",
        "                                  )\n",
        "  iris_target_pdf = pd.DataFrame(data={'species': iris_target}) \\\n",
        "                      .replace(to_replace={n:iris_target_names[n]\n",
        "                                           for n in [0,1,2]}) \\\n",
        "                      .astype('object')\n",
        "  iris_pdf = pd.concat([iris_features_pdf, iris_target_pdf],\n",
        "                       axis='columns',\n",
        "                       join='inner')\n",
        "  return iris_pdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBtVd7-jUxNI",
        "colab_type": "text"
      },
      "source": [
        "Notice that the column names have been changed to use snake case, the parentheses have been removed from the feature column names, and the target column has been named `species` and its integer values replaced with corresponding strings. \n",
        "\n",
        "Store the data frame in `initial_pdf` for input to the next step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w588FI7APVi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_pdf = get_iris_pdf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyBtirBmXsSp",
        "colab_type": "text"
      },
      "source": [
        "Notice that the datatypes look correct. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnHZi9_UUrrF",
        "colab_type": "code",
        "outputId": "71a19a23-01ad-461f-884e-2ebde8969ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "initial_pdf.info()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            "sepal_length_cm    150 non-null float64\n",
            "sepal_width_cm     150 non-null float64\n",
            "petal_length_cm    150 non-null float64\n",
            "petal_width_cm     150 non-null float64\n",
            "species            150 non-null object\n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 5.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG_mwcCvXzGh",
        "colab_type": "code",
        "outputId": "afedc819-cdd1-4a09-e3aa-74a3cf492eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "initial_pdf.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length_cm</th>\n",
              "      <th>sepal_width_cm</th>\n",
              "      <th>petal_length_cm</th>\n",
              "      <th>petal_width_cm</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm species\n",
              "0              5.1             3.5              1.4             0.2  setosa\n",
              "1              4.9             3.0              1.4             0.2  setosa\n",
              "2              4.7             3.2              1.3             0.2  setosa\n",
              "3              4.6             3.1              1.5             0.2  setosa\n",
              "4              5.0             3.6              1.4             0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPlDO6HNXjWU",
        "colab_type": "code",
        "outputId": "ed78f84e-a9ed-4591-d3f6-2b44de9fcffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "initial_pdf['species'].value_counts()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "versicolor    50\n",
              "virginica     50\n",
              "setosa        50\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B7izFb6Xxqx",
        "colab_type": "text"
      },
      "source": [
        "The `get_iris_pdf` function returns a pandas dataframe with columns that have correct datatypes, which is the primary concern at this step. This dataframe will be passed to the next step, which creates a feature-target dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_SzjnpPJ4al",
        "colab_type": "text"
      },
      "source": [
        "### Step 2. Create feature-target dataframe by preprocessing initial dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g27AdQ5SZ8vd",
        "colab_type": "text"
      },
      "source": [
        "This step takes as input the initial dataframe produced by the previous step and returns a dataframe with a target variable and predictor variables. In general this step consists of only per row transformations of the initial dataframe, which __do not__ use aggregate data summarized across the entire dataframe. Later notebooks will focus on this constraint.\n",
        "\n",
        "In addition, it is essential that the target column does not include any missing values.\n",
        "\n",
        "In this example, the only work involved is to\n",
        "- drop rows where `species` is equal to `setosa`\n",
        "- rename the `species` column  to `target` \n",
        "\n",
        "Below this work is done by the  _transformer object_ `IrisFeaTgtPDF()` that is returned by the function `get_prepare_transformer_object`.  Using a transformer class doesn't seem useful now, but it will later when things get more complicated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWlin2Sgh7Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class IrisFeaTgtPDF(BaseEstimator, TransformerMixin):  \n",
        "  def __init__(self):\n",
        "    return\n",
        "    \n",
        "  def fit(self, X, y=None): \n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None): \n",
        "    return X.loc[lambda pdf: pdf.species!='setosa'] \\\n",
        "            .rename(columns={'species':'target'})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Qg9882Yu1i",
        "colab_type": "text"
      },
      "source": [
        "The `get_feature_target_pdf` function passes the pandas dataframe `pdf` to the `fit` and `transform` methods of the `transformer_object`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm4W3u-A3Y3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_target_pdf(pdf, transformer_object): \n",
        "  return transformer_object.fit(pdf).transform(pdf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iEtngmsFuyN",
        "colab_type": "text"
      },
      "source": [
        "This function is called with the initial dataframe as input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyCMFjrv-jhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_target_pdf = get_feature_target_pdf(initial_pdf, \n",
        "                                            IrisFeaTgtPDF()\n",
        "                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvoGvInMPvPk",
        "colab_type": "code",
        "outputId": "83ae9b0f-1d14-420e-b15e-3f35a7facf25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "feature_target_pdf.info()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 100 entries, 50 to 149\n",
            "Data columns (total 5 columns):\n",
            "sepal_length_cm    100 non-null float64\n",
            "sepal_width_cm     100 non-null float64\n",
            "petal_length_cm    100 non-null float64\n",
            "petal_width_cm     100 non-null float64\n",
            "target             100 non-null object\n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 4.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zodYyUlRPzYM",
        "colab_type": "code",
        "outputId": "07891b5d-aa5b-4892-c3cc-972029551978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "feature_target_pdf['target'].value_counts()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "versicolor    50\n",
              "virginica     50\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrjOlPXBJ6p1",
        "colab_type": "text"
      },
      "source": [
        "### Step 3. Create train and test datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3xY_zleGfzV",
        "colab_type": "text"
      },
      "source": [
        "This is a simple, but important step in the process. Steps 4 and 5 (step 4 creates the model, step 5 evaluates the model's predictions) must use different datasets. In particular, step 4 uses the train dataset and step 5 uses the test dataset. Otherwise, there is no reason to believe that the results for predictions on unseen data would be similar to your evaluation of the model's results. In particular, \n",
        "- The model is fit to the train dataset\n",
        "- Predictions are made from the predictor variables of the test dataset\n",
        "- These predictions are compared to the target variable of the test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4lDyDtnri92",
        "colab_type": "text"
      },
      "source": [
        "The Scikit-learn library makes available the `train_test_split` function that creates train and test datasets. This function is _wrapped_ below to create a function that takes as input a dataframe and the name of the target variable and returns a dictionary of results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMEa41-EInnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_test_dict(pdf, target_name, **kwargs):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(pdf.drop(columns=target_name),\n",
        "                                                      pdf[target_name], \n",
        "                                                      **kwargs)\n",
        "  return {\n",
        "      'x_train': X_train,\n",
        "      'y_train': y_train,\n",
        "      'x_test' : X_test,\n",
        "      'y_test' : y_test\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCKKXiL7J44S",
        "colab_type": "code",
        "outputId": "e104163a-b876-43c7-8f24-a3b4f0e57cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_test_dict = get_train_test_dict(feature_target_pdf,'target')\n",
        "train_test_dict.keys()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['x_train', 'y_train', 'x_test', 'y_test'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWhtg7eZa7_8",
        "colab_type": "text"
      },
      "source": [
        "Notice the differences in datatype and shape of the output. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBmJBSpHRSIS",
        "colab_type": "code",
        "outputId": "5713f241-da34-4cd6-b596-948d16cf8be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "[(name, type(val), val.shape) for (name,val) in train_test_dict.items()]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('x_train', pandas.core.frame.DataFrame, (75, 4)),\n",
              " ('y_train', pandas.core.series.Series, (75,)),\n",
              " ('x_test', pandas.core.frame.DataFrame, (25, 4)),\n",
              " ('y_test', pandas.core.series.Series, (25,))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhWL87NjJ8OQ",
        "colab_type": "text"
      },
      "source": [
        "### Step 4. Fit model \n",
        "\n",
        "A _model_ is _fit_ on a training dataset so that it (the fit model) can be used to make predictions on unseen datasets (that contain the same predictor columns as the training dataset). \n",
        "\n",
        "Linear regression and logistic regression are common models. When they are fit to a training dataset then coefficients are determined for each predictor column/variable that are then used to make predictions from a row of values with values for these predictor variables.\n",
        "\n",
        "This is accomplished in Python using the Scikit-learn library with estimator objects that have `fit` and `predict` methods. The `fit` method takes as input `x_train` (the predictor train dataframe) and `y_train` (the target train series). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLCWMp6iRt2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fit_model(estimator_object, x_train, y_train):\n",
        "  return estimator_object.fit(X=x_train,\n",
        "                              y=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr6M-UMne6JQ",
        "colab_type": "text"
      },
      "source": [
        "The `get_fit_model` function (defined above) is called with transformer object `LogisticRegression()`  and with the predictor training dataframe and the target training series. The function returns the fit model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-_VJ7_KSet3",
        "colab_type": "code",
        "outputId": "28f677bd-6c26-4544-aef1-fa18d6170083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "fit_model = get_fit_model(estimator_object=LogisticRegression(solver='lbfgs'),\n",
        "                          x_train         =train_test_dict.get('x_train'),\n",
        "                          y_train         =train_test_dict.get('y_train'),\n",
        "                         )\n",
        "fit_model"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVVIfr7hJ9-O",
        "colab_type": "text"
      },
      "source": [
        "### Step 5. Make and evaluate predictions \n",
        "\n",
        "After a model has been fit to the training datasets it can then be used to make predictions using the `predict` method (of the model). The `get_predict_ser` function takes as input a fit model and a predictor dataframe and returns a prediction series. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n_Ud0SZVIqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predict_ser(model, x_test):\n",
        "  return model.predict(X=x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ-EGtn3gPsi",
        "colab_type": "text"
      },
      "source": [
        "As the name of the `x_test` parameter suggests that parameter value should be the test predictor dataframe. As mentioned above, it is important to use different datasets for model evaluation (the test dataset) and for model fitting (the train dataset). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMN4cyKnubaW",
        "colab_type": "text"
      },
      "source": [
        "Create a pandas series of predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSAGYcBJZFrr",
        "colab_type": "code",
        "outputId": "9f2852cb-3d76-4108-a961-323fd9b4e264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "predict_ser = get_predict_ser(model =fit_model, \n",
        "                              x_test=train_test_dict.get('x_test')\n",
        "                             )\n",
        "(train_test_dict.get('y_test').shape, \n",
        " predict_ser.shape, \n",
        " predict_ser[:5]\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25,),\n",
              " (25,),\n",
              " array(['virginica', 'virginica', 'versicolor', 'versicolor', 'versicolor'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMXG4V6RhOe6",
        "colab_type": "text"
      },
      "source": [
        "The `get_actual_predict_pdf` function (below) simply creates a dataframe with one column for actual values and one column for predicted values. In addition, the dataframe index is set to be the same as the index of the actual values (target test series). The index will be useful when working with time series. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "But2R3raWHKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual_predict_pdf(actual,predict):\n",
        "  import pandas as pd\n",
        "  return pd.DataFrame(data={'actual' : actual,\n",
        "                            'predict': predict},\n",
        "                      index=actual.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8BSKoVnhyio",
        "colab_type": "text"
      },
      "source": [
        "This function is run with input of the test target series and the predictions made from the test predictor dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIsK0Ubsm25J",
        "colab_type": "code",
        "outputId": "0905c11a-2130-4512-8950-57e02af1315f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "actual_predict_pdf = get_actual_predict_pdf(train_test_dict.get('y_test'),\n",
        "                                            get_predict_ser(fit_model,train_test_dict.get('x_test'))\n",
        "                                           ) \n",
        "actual_predict_pdf.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>virginica</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         actual     predict\n",
              "104   virginica   virginica\n",
              "70   versicolor   virginica\n",
              "54   versicolor  versicolor\n",
              "88   versicolor  versicolor\n",
              "67   versicolor  versicolor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5EGB745iOf5",
        "colab_type": "text"
      },
      "source": [
        "Notice the values and the count of differences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CEXrVKEiVqX",
        "colab_type": "code",
        "outputId": "ae50e494-2f81-4754-a71f-6a99c3fef4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(    actual_predict_pdf['actual']\n",
        " .ne(actual_predict_pdf['predict'])\n",
        " .sum()\n",
        ")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6der_i5Pi1pI",
        "colab_type": "text"
      },
      "source": [
        "The `get_actual_predict_eval` function takes as input a metric function and a dataframe with columns named `actual` and `predict`. It returns the result of applying the metric to the two columns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGUhm8TRr2Np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual_predict_eval(actual_predict_pdf, metric_function):\n",
        "  return metric_function(actual_predict_pdf['actual'], \n",
        "                         actual_predict_pdf['predict']\n",
        "                        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6XWvrgrr-4n",
        "colab_type": "code",
        "outputId": "942b0fd5-2732-4df6-99b6-8244a5735246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "get_actual_predict_eval(actual_predict_pdf=actual_predict_pdf,\n",
        "                        metric_function   =accuracy_score\n",
        "                       )"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVk-WDdS7x66",
        "colab_type": "text"
      },
      "source": [
        "## Workflow - essentials\n",
        "\n",
        "The code cell below collects only the essential commands to implement the workflow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjGfTOmXwTyl",
        "colab_type": "code",
        "outputId": "a8392228-83ac-4cb6-ae45-d292789f5345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "initial_pdf = get_iris_pdf() # workflow component\n",
        "\n",
        "feature_target_pdf = \\\n",
        "get_feature_target_pdf(pdf               =initial_pdf, \n",
        "                       transformer_object=IrisFeaTgtPDF() # workflow component\n",
        "                      )\n",
        "\n",
        "train_test_dict = \\\n",
        "get_train_test_dict(pdf        =feature_target_pdf,\n",
        "                    target_name='target'\n",
        "                   )\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression # workflow component\n",
        "\n",
        "fit_model = \\\n",
        "get_fit_model(estimator_object=LogisticRegression(solver='lbfgs'), # workflow component\n",
        "              x_train         =train_test_dict.get('x_train'),\n",
        "              y_train         =train_test_dict.get('y_train'),\n",
        "             )\n",
        "\n",
        "actual_predict_pdf = \\\n",
        "get_actual_predict_pdf(                          train_test_dict.get('y_test'),\n",
        "                       get_predict_ser(fit_model,train_test_dict.get('x_test'))\n",
        "                      ) \n",
        "\n",
        "from sklearn.metrics import accuracy_score # workflow component\n",
        "\n",
        "get_actual_predict_eval(actual_predict_pdf,\n",
        "                        accuracy_score # workflow component\n",
        "                       )"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk1c1RNrH-_B",
        "colab_type": "text"
      },
      "source": [
        "## Workflow - function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpPHA1h6s8iG",
        "colab_type": "text"
      },
      "source": [
        "In the next section the standard functions (used above) are defined. In the section following the four components are defined. At the end of the second section the `workflow` function (one of the \"standard\" functions) is run with these components as input. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqpsEcPwzt4N",
        "colab_type": "text"
      },
      "source": [
        "### Standard/common functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5AnRZV5RTt",
        "colab_type": "text"
      },
      "source": [
        "The following code cells contains the standard functions defined above. (Does not include `get_iris_pdf`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjqgBXU6zIyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_target_pdf(pdf, transformer_object): \n",
        "  return transformer_object.fit(pdf).transform(pdf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ybrqPvmzCO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_test_dict(pdf, target_name, **kwargs):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(pdf.drop(columns=target_name),\n",
        "                                                      pdf[target_name], \n",
        "                                                      **kwargs)\n",
        "  return {\n",
        "      'x_train': X_train,\n",
        "      'y_train': y_train,\n",
        "      'x_test' : X_test,\n",
        "      'y_test' : y_test\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNgrpiDLy9u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fit_model(estimator_object, x_train, y_train):\n",
        "  return estimator_object.fit(X=x_train,\n",
        "                              y=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcICL08Ey5aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predict_ser(model, x_test):\n",
        "  return model.predict(X=x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub7PyriPy0hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual_predict_pdf(actual,predict):\n",
        "  import pandas as pd\n",
        "  return pd.DataFrame(data={'actual' : actual,\n",
        "                            'predict': predict},\n",
        "                      index=actual.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWTMXPcNyly7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_actual_predict_eval(actual_predict_pdf, metric_function):\n",
        "  return metric_function(actual_predict_pdf['actual'], \n",
        "                         actual_predict_pdf['predict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvMmQfk-5d5n",
        "colab_type": "text"
      },
      "source": [
        "The `workflow` function bundles these standard functions together and takes as input the four workflow components. \n",
        "\n",
        "The result is the evaluation of the predictions \n",
        "- made on the test dataset by the model, \n",
        "- which was fit to the train dataset, \n",
        "- which was split from the feature-target dataset \n",
        "- which was prepared from the initial dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clNLYJNiII6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def workflow(initial_pdf,        # workflow component\n",
        "             transformer_object, # workflow component\n",
        "             estimator_object,   # workflow component\n",
        "             metric_function     # workflow component\n",
        "            ):\n",
        "  feature_target_pdf = \\\n",
        "  get_feature_target_pdf(pdf               =initial_pdf,       # workflow component\n",
        "                         transformer_object=transformer_object # workflow component\n",
        "                        )\n",
        "\n",
        "  train_test_dict = \\\n",
        "  get_train_test_dict(pdf        =feature_target_pdf,\n",
        "                      target_name='target'\n",
        "                     )\n",
        "\n",
        "  fit_model = \\\n",
        "  get_fit_model(estimator_object=estimator_object, # workflow component\n",
        "                x_train         =train_test_dict.get('x_train'),\n",
        "                y_train         =train_test_dict.get('y_train'),\n",
        "               )\n",
        "\n",
        "  actual_predict_pdf = \\\n",
        "  get_actual_predict_pdf(train_test_dict.get('y_test'),\n",
        "                         get_predict_ser(fit_model,\n",
        "                                         train_test_dict.get('x_test')\n",
        "                                        )\n",
        "                        ) \n",
        "\n",
        "  return get_actual_predict_eval(actual_predict_pdf,\n",
        "                                 metric_function # workflow component\n",
        "                                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoBQ3XjCz-_N",
        "colab_type": "text"
      },
      "source": [
        "### Components specific to the iris dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lWMPfF26INQ",
        "colab_type": "text"
      },
      "source": [
        "The first component is the initial dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYR6yf_0M23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_iris_pdf(): \n",
        "  import pandas as pd\n",
        "  from sklearn.datasets import load_iris\n",
        "  iris_features     = load_iris().data\n",
        "  iris_target       = load_iris().target\n",
        "  iris_target_names = load_iris().target_names\n",
        "\n",
        "  iris_feature_columns = [feature_name.replace(' ','_')\n",
        "                                      .replace('(','')\n",
        "                                      .replace(')','') \n",
        "                          for feature_name in load_iris().get('feature_names')]\n",
        "  \n",
        "  iris_features_pdf = pd.DataFrame(data=iris_features,\n",
        "                                   columns=iris_feature_columns\n",
        "                                  )\n",
        "  iris_target_pdf = pd.DataFrame(data={'species': iris_target}) \\\n",
        "                      .replace(to_replace={n:iris_target_names[n]\n",
        "                                           for n in [0,1,2]}) \\\n",
        "                      .astype('object')\n",
        "  iris_pdf = pd.concat([iris_features_pdf, iris_target_pdf],\n",
        "                       axis='columns',\n",
        "                       join='inner')\n",
        "  return iris_pdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBm3bMfP6NDX",
        "colab_type": "text"
      },
      "source": [
        "The second component is the transformer object that creates the feature-target dataset from the initial dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl5bM5_G0TG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class IrisFeaTgtPDF(BaseEstimator, TransformerMixin):  \n",
        "  def __init__(self):\n",
        "    return\n",
        "    \n",
        "  def fit(self, X, y=None): \n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None): \n",
        "    return X.loc[lambda pdf: pdf.species!='setosa'] \\\n",
        "            .rename(columns={'species':'target'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6DSkM5a6ZBt",
        "colab_type": "text"
      },
      "source": [
        "The last two components are the estimator object and the metric function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuYUA7nEIYrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics      import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyccQFXW6kE6",
        "colab_type": "text"
      },
      "source": [
        "These four components are input to the `workflow` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEs5WDsg6hIj",
        "colab_type": "code",
        "outputId": "ad086bb5-0e21-4fa1-effd-e2538a4667cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "workflow(initial_pdf       =get_iris_pdf(),\n",
        "         transformer_object=IrisFeaTgtPDF(),\n",
        "         estimator_object  =LogisticRegression(solver='lbfgs'),\n",
        "         metric_function   =accuracy_score\n",
        "        )"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETDzlw6QTQaP",
        "colab_type": "text"
      },
      "source": [
        "## Workflow - Boston housing dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW8Ws4bCJrO5",
        "colab_type": "text"
      },
      "source": [
        "The four components of the Boston housing dataset workflow are listed in the following three code cells. They are: \n",
        "- the initial dataframe returned by the `get_boston_housing_pdf` function\n",
        "- the transformer object `BostonHousingFeaTgtPDF()` that creates the feature-target dataframe\n",
        "- the `LinearRegression()` estimator object\n",
        "- the `mean_absolute_error` metric function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAz076NnBLSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_boston_housing_pdf(): # for boston housing dataset\n",
        "  from sklearn.datasets import load_boston\n",
        "  feature_names = [name.lower() \n",
        "                   for name in load_boston().get('feature_names').tolist()\n",
        "                  ]\n",
        "  features_pdf = pd.DataFrame(data=load_boston().get('data'),\n",
        "                              columns=feature_names\n",
        "                             )\n",
        "  target_pdf = pd.DataFrame(data={'price': load_boston().get('target')}\n",
        "                           )\n",
        "  return pd.concat([features_pdf, target_pdf],\n",
        "                   axis='columns',\n",
        "                   join='inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VxHwFT9D8RR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class BostonHousingFeaTgtPDF(BaseEstimator, TransformerMixin):  \n",
        "  def __init__(self):\n",
        "    return\n",
        "    \n",
        "  def fit(self, X, y=None): \n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None): \n",
        "    return X.rename(columns={'price':'target'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QhXXJQJwni3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics      import mean_absolute_error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MJ-TJF67iwr",
        "colab_type": "text"
      },
      "source": [
        "These components are input to the `workflow` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gROBTx5668RW",
        "colab_type": "code",
        "outputId": "dfd811a1-db28-478f-c4b7-67271c74818c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "workflow(initial_pdf       =get_boston_housing_pdf(),\n",
        "         transformer_object=BostonHousingFeaTgtPDF(),\n",
        "         estimator_object  =LinearRegression(),\n",
        "         metric_function   =mean_absolute_error\n",
        "        )"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.3255383928596514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6-1mm7eCyo1",
        "colab_type": "text"
      },
      "source": [
        "## Workflow - Diamonds dataset (hands-on)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnUs-K07Boon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_diamonds_pdf():\n",
        "  import pandas as pd\n",
        "  diamonds_file_link = 'https://raw.githubusercontent.com/datalab-datasets/file-samples/master/diamonds.csv'\n",
        "  return pd.read_csv(diamonds_file_link) \\\n",
        "           .drop('Unnamed: 0',\n",
        "                 axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUZ9n2jM8SCo",
        "colab_type": "code",
        "outputId": "63dfdc87-b35c-4948-c85f-dc3d1e246b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "get_diamonds_pdf().info()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53940 entries, 0 to 53939\n",
            "Data columns (total 10 columns):\n",
            "carat      53940 non-null float64\n",
            "cut        53940 non-null object\n",
            "color      53940 non-null object\n",
            "clarity    53940 non-null object\n",
            "depth      53940 non-null float64\n",
            "table      53940 non-null float64\n",
            "price      53940 non-null int64\n",
            "x          53940 non-null float64\n",
            "y          53940 non-null float64\n",
            "z          53940 non-null float64\n",
            "dtypes: float64(6), int64(1), object(3)\n",
            "memory usage: 4.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRuSklcV8BnM",
        "colab_type": "text"
      },
      "source": [
        "Add code to the `transform` method of the `DiamondsFeaTgtPDF` class to drop all of the `object` columns. Use the pandas `select_dtypes` function to do so. See: \n",
        "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I31SwvweCSlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class DiamondsFeaTgtPDF(BaseEstimator, TransformerMixin):  \n",
        "  def __init__(self):\n",
        "    return\n",
        "    \n",
        "  def fit(self, X, y=None): \n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None): \n",
        "    return X.rename(columns={'price':'target'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frGVddQ9CghF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics      import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRHyZdKa8mzu",
        "colab_type": "text"
      },
      "source": [
        "The following function call to `workflow` will produce an error. (The third and fourth parameters are missing.)\n",
        "\n",
        "Supply appropriate values to the `estimator_object`  and `metric_function` parameters (the missing third and fourth parameters). Then run the `workflow` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhlsmd-S8fnQ",
        "colab_type": "code",
        "outputId": "8a89fda1-c274-43ba-cdf4-7e701e8e0bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "workflow(initial_pdf       =get_diamonds_pdf(),\n",
        "         transformer_object=DiamondsFeaTgtPDF(),\n",
        "         estimator_object  =___, # supply an appropriate estimator object\n",
        "         metric_function   =___  # supply an appropriate metric function\n",
        "        )"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-74db89ae015a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m          \u001b[0mtransformer_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDiamondsFeaTgtPDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0mestimator_object\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0m___\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# supply an appropriate estimator object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m          \u001b[0mmetric_function\u001b[0m   \u001b[0;34m=\u001b[0m\u001b[0m___\u001b[0m  \u001b[0;31m# supply an appropriate metric function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-77-3043bbb50bb5>\u001b[0m in \u001b[0;36mworkflow\u001b[0;34m(initial_pdf, transformer_object, estimator_object, metric_function)\u001b[0m\n\u001b[1;32m     14\u001b[0m   fit_model =   get_fit_model(estimator_object=estimator_object, # workflow component\n\u001b[1;32m     15\u001b[0m                 \u001b[0mx_train\u001b[0m         \u001b[0;34m=\u001b[0m\u001b[0mtrain_test_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0my_train\u001b[0m         \u001b[0;34m=\u001b[0m\u001b[0mtrain_test_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-528fe634a369>\u001b[0m in \u001b[0;36mget_fit_model\u001b[0;34m(estimator_object, x_train, y_train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   return estimator_object.fit(X=x_train,\n\u001b[0m\u001b[1;32m      3\u001b[0m                               y=y_train)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'fit'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTVTIsDYMff9",
        "colab_type": "text"
      },
      "source": [
        "## Next steps\n",
        "- Extend the estimator pipeline with transformer and estimator classes from Scikit-learn\n",
        "- Extend the transformer pipeline with DIY classes that wrap Scikit-learn transformer classes\n",
        "- Use grid search and cross validation to evaluate multiple models and hyper-parameters\n",
        "- Work with time series datasets \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPELgd8mRPHG",
        "colab_type": "text"
      },
      "source": [
        "__The End__"
      ]
    }
  ]
}